{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 12 22:27:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 8000                Off | 00000000:23:00.0 Off |                  Off |\n",
      "| 33%   37C    P5              27W / 260W |      6MiB / 49152MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12\n",
    "#%pip install cucim-cu12 cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.11/dist-packages (2024.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.9.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2024.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 22:27:24.087000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-12 22:27:24.118966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-12 22:27:24.128779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-12 22:27:24.156396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set GPU memory limit to 16GB.\n",
      "Is tensorflow using cuda?  True\n",
      "Is pandas using cuda?  <module 'pandas' from '/usr/local/lib/python3.11/dist-packages/pandas/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "#%load_ext cudf.pandas\n",
    "\n",
    "# To desable GPU usage\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "#from cucim.skimage.exposure import rescale_intensity\n",
    "import tensorflow as tf\n",
    "#import cupy as cp\n",
    "#import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # memory limit 16GB (16 * 1024 MB = 16384 MB) \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=16384)] \n",
    "        )\n",
    "        print(\"Set GPU memory limit to 16GB.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory limit:\", e)\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "\n",
    "#print(\"Is torch using cuda? \",torch.cuda.is_available())\n",
    "print(\"Is tensorflow using cuda? \",tf.test.is_built_with_cuda())\n",
    "print(\"Is pandas using cuda? \",pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = [\n",
    "    \"box\",\n",
    "    \"circularTorus\",\n",
    "    \"cone\",\n",
    "    \"coneOffset\",\n",
    "    \"cylinder\",\n",
    "    \"cylinderSlope\",\n",
    "    \"dish\",\n",
    "    \"mesh\",\n",
    "    \"pyramid\",\n",
    "    \"rectangularTorus\",\n",
    "    \"sphere\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_number(texts:list[str]):\n",
    "    def key(text:str):\n",
    "        text = re.sub(r'.*photos_', '', text)\n",
    "        text = re.sub(r'\\.csv', '', text)\n",
    "        text = re.sub(r'\\D', '', text)\n",
    "        return int(text)\n",
    "    return sorted(texts, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "base_path = '/home/workspace/geometry-classifier/data/'\n",
    "parquet_files = glob.glob(base_path + 'photos_v3_parquet/*.parquet')\n",
    "\n",
    "def data_generator():\n",
    "    counter = 0\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    for file in parquet_files:\n",
    "        df = pd.read_parquet(file)\n",
    "        \n",
    "\n",
    "        df = df.drop(columns=['id'], axis=1)\n",
    "        df['name'] = encoder.fit_transform(df['name'])\n",
    "        \n",
    "        X_train, X_aux, y_train, y_aux = train_test_split(df.drop(columns=[\"name\"]), df['name'], test_size=0.4, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_aux, y_aux, test_size=0.5, random_state=42)\n",
    "        \n",
    "        if len(X_train) != len(y_train) or len(X_val) != len(y_val):\n",
    "            raise ValueError(\"Mismatch in number of samples between features and labels\")\n",
    "        \n",
    "        if counter % 5 == 0:\n",
    "            training_file = f\"training_{counter // 5}.parquet\"\n",
    "            training_df = pd.DataFrame(X_train)\n",
    "            training_df['name'] = y_train\n",
    "            training_df.to_parquet(base_path + f\"training/{training_file}\")\n",
    "        \n",
    "        X = np.array([x.reshape(224, 224, 1).astype(np.uint8) for x in X_train.to_numpy()])\n",
    "        X_val = np.array([x.reshape(224, 224, 1).astype(np.uint8) for x in X_val.to_numpy()])\n",
    "        \n",
    "        Y = y_train.values\n",
    "        y_val = y_val.values\n",
    "\n",
    "        yield X, Y, X_val, y_val\n",
    "        \n",
    "        del df, X_train, y_train, X_test, y_test, Y, X, X_val, y_val, X_aux, y_aux\n",
    "        gc.collect()\n",
    "        \n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-12 22:27:27.939941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16384 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:23:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# 224 x 224\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = models.Sequential([\n",
    "\n",
    "    layers.Conv2D(8, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(10, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m73/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m70/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m73/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m76/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m69/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.9563\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.9662 - val_accuracy: 0.9561 - val_loss: 0.7191\n",
      "\u001b[1m69/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m70/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m73/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m71/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m72/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1921e-07\n",
      "Epoch 1: val_loss did not improve from 0.00000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model copy.ipynb Célula 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpochs \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m X_train, Y_train, X_val, Y_val \u001b[39min\u001b[39;49;00m data_generator():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         cnn \u001b[39m=\u001b[39;49m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback], batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, Y_val), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model copy.ipynb Célula 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m parquet_files:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(file)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Drop unnecessary columns and encode labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_model%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    668\u001b[0m     path,\n\u001b[1;32m    669\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    670\u001b[0m     filters\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m    671\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    672\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    673\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    674\u001b[0m     filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m    675\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    676\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:403\u001b[0m, in \u001b[0;36mFastParquetImpl.read\u001b[0;34m(self, path, columns, filters, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     parquet_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mParquetFile(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparquet_kwargs)\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m parquet_file\u001b[39m.\u001b[39;49mto_pandas(columns\u001b[39m=\u001b[39;49mcolumns, filters\u001b[39m=\u001b[39;49mfilters, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    404\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39mif\u001b[39;00m handles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastparquet/api.py:790\u001b[0m, in \u001b[0;36mParquetFile.to_pandas\u001b[0;34m(self, columns, categories, filters, index, row_filter, dtypes)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     parts \u001b[39m=\u001b[39m {name: (v \u001b[39mif\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m-catdef\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    788\u001b[0m                     \u001b[39melse\u001b[39;00m v[start:start \u001b[39m+\u001b[39m thislen])\n\u001b[1;32m    789\u001b[0m              \u001b[39mfor\u001b[39;00m (name, v) \u001b[39min\u001b[39;00m views\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 790\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_row_group_file(rg, columns, categories, index,\n\u001b[1;32m    791\u001b[0m                              assign\u001b[39m=\u001b[39;49mparts, partition_meta\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartition_meta,\n\u001b[1;32m    792\u001b[0m                              row_filter\u001b[39m=\u001b[39;49msel, infile\u001b[39m=\u001b[39;49minfile)\n\u001b[1;32m    793\u001b[0m     start \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m thislen\n\u001b[1;32m    794\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastparquet/api.py:388\u001b[0m, in \u001b[0;36mParquetFile.read_row_group_file\u001b[0;34m(self, rg, columns, categories, index, assign, partition_meta, row_filter, infile)\u001b[0m\n\u001b[1;32m    385\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    386\u001b[0m f \u001b[39m=\u001b[39m infile \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(fn, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 388\u001b[0m core\u001b[39m.\u001b[39;49mread_row_group(\n\u001b[1;32m    389\u001b[0m     f, rg, columns, categories, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschema, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcats,\n\u001b[1;32m    390\u001b[0m     selfmade\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselfmade, index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    391\u001b[0m     assign\u001b[39m=\u001b[39;49massign, scheme\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_scheme, partition_meta\u001b[39m=\u001b[39;49mpartition_meta,\n\u001b[1;32m    392\u001b[0m     row_filter\u001b[39m=\u001b[39;49mrow_filter\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastparquet/core.py:644\u001b[0m, in \u001b[0;36mread_row_group\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, index, assign, scheme, partition_meta, row_filter)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mif\u001b[39;00m assign \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mGoing with pre-allocation!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 644\u001b[0m read_row_group_arrays(file, rg, columns, categories, schema_helper,\n\u001b[1;32m    645\u001b[0m                       cats, selfmade, assign\u001b[39m=\u001b[39;49massign, row_filter\u001b[39m=\u001b[39;49mrow_filter)\n\u001b[1;32m    647\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m cats:\n\u001b[1;32m    648\u001b[0m     \u001b[39mif\u001b[39;00m cat \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m assign:\n\u001b[1;32m    649\u001b[0m         \u001b[39m# do no need to have partition columns in output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastparquet/core.py:613\u001b[0m, in \u001b[0;36mread_row_group_arrays\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, assign, row_filter)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns \u001b[39mor\u001b[39;00m name \u001b[39min\u001b[39;00m cats:\n\u001b[1;32m    612\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m remains\u001b[39m.\u001b[39mdiscard(name)\n\u001b[1;32m    615\u001b[0m read_col(column, schema_helper, file, use_cat\u001b[39m=\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-catdef\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m out,\n\u001b[1;32m    616\u001b[0m          selfmade\u001b[39m=\u001b[39mselfmade, assign\u001b[39m=\u001b[39mout[name],\n\u001b[1;32m    617\u001b[0m          catdef\u001b[39m=\u001b[39mout\u001b[39m.\u001b[39mget(name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-catdef\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    618\u001b[0m          row_filter\u001b[39m=\u001b[39mrow_filter)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m _is_map_like(schema_helper, column):\n\u001b[1;32m    621\u001b[0m     \u001b[39m# TODO: could be done in fast loop in _assemble_objects?\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(base_path+'model.keras',save_best_only=True, save_weights_only=False, mode='min', verbose=1)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for i in range(100):\n",
    "    print(f\"Epochs {i+1}/{epochs}\")\n",
    "    j = 0\n",
    "    for X_train, Y_train, X_val, Y_val in data_generator():\n",
    "        j+=1\n",
    "        print(f\"Datasets: {j}/1042\")\n",
    "        cnn = model.fit(X_train,Y_train, epochs=1, callbacks=[checkpoint_callback], batch_size=8, validation_data=(X_val, Y_val), verbose=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
