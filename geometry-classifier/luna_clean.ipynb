{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No devices were found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12\n",
    "#%pip install cucim-cu12 cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fastparquet) (1.26.4)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2024.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.9.0 fastparquet-2024.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:19:45.897682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-30 03:19:45.928979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-30 03:19:45.938601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-30 03:19:45.963108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs available.\n",
      "Is tensorflow using cuda?  True\n",
      "Is pandas using cuda?  <module 'pandas' from '/usr/local/lib/python3.11/dist-packages/pandas/__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:19:49.487163: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    }
   ],
   "source": [
    "#%load_ext cudf.pandas\n",
    "\n",
    "# To desable GPU usage\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "#from cucim.skimage.exposure import rescale_intensity\n",
    "import tensorflow as tf\n",
    "#import cupy as cp\n",
    "#import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # memory limit 16GB (16 * 1024 MB = 16384 MB) \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=16384)] \n",
    "        )\n",
    "        print(\"Set GPU memory limit to 16GB.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory limit:\", e)\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "\n",
    "#print(\"Is torch using cuda? \",torch.cuda.is_available())\n",
    "print(\"Is tensorflow using cuda? \",tf.test.is_built_with_cuda())\n",
    "print(\"Is pandas using cuda? \",pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = [\n",
    "    \"box\",\n",
    "    \"circularTorus\",\n",
    "    \"cone\",\n",
    "    \"coneOffset\",\n",
    "    \"cylinder\",\n",
    "    \"cylinderSlope\",\n",
    "    \"dish\",\n",
    "    \"mesh\",\n",
    "    \"pyramid\",\n",
    "    \"rectangularTorus\",\n",
    "    \"sphere\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_parquet.parquet  no-stratTF1\t\t    tfr_strat50-1min\n",
      "model1.keras\t     photos_v3_parquet\t\t    tfrecord\n",
      "model4.keras\t     tfr_strat100-2min\t\t    tfrecord2\n",
      "no-strat\t     tfr_strat100-2min-notfiltered  training\n"
     ]
    }
   ],
   "source": [
    "!ls /home/workspace/geometry-classifier/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train462.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train462.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train153.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train153.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test54.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test54.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train314.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train314.tfrecord.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:33:24.867141: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train374.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train374.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train259.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train259.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test17.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test17.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train204.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train204.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train68.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train68.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train230.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train230.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test106.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test106.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train235.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train235.tfrecord.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:33:54.809064: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train43.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train43.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train223.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train223.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/val18.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/val18.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train381.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train381.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test8.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test8.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train285.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train285.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test134.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test134.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/val19.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/val19.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test133.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test133.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test15.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test15.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train82.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train82.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train178.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train178.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train142.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train142.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/val104.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/val104.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train379.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train379.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/val128.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/val128.tfrecord.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:34:50.756751: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train101.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train101.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train143.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train143.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/train28.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/train28.tfrecord.gz\n",
      "Processing /home/workspace/geometry-classifier/data/tfr_strat100-2min-notfiltered/test98.tfrecord.gz -> /home/workspace/geometry-classifier/data/tfr_strat100-2min/test98.tfrecord.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb Célula 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00minput_path\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00moutput_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m         filter_tfrecord(input_path, output_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m process_tfrecord_folder(base_path\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtfr_strat100-2min-notfiltered\u001b[39;49m\u001b[39m\"\u001b[39;49m, base_path\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtfr_strat100-2min\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m#glob.glob(base_path+\"tfr_strat100-2min-notfiltered/*.tfrecord.gz\")\u001b[39;00m\n",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb Célula 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m output_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00minput_path\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00moutput_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m filter_tfrecord(input_path, output_path)\n",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb Célula 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m raw_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTFRecordDataset(input_path, compression_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGZIP\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m raw_record \u001b[39min\u001b[39;00m raw_dataset:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     image, class_label \u001b[39m=\u001b[39m parse_tfrecord(raw_record)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mif\u001b[39;00m class_label \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:  \u001b[39m# Filter out class -1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         serialized_example \u001b[39m=\u001b[39m serialize_example(tf\u001b[39m.\u001b[39mconvert_to_tensor(image), tf\u001b[39m.\u001b[39mconvert_to_tensor(class_label))\n",
      "\u001b[1;32m/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb Célula 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m parsed_example \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mparse_single_example(example_proto, feature_description)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m name \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mdecode_raw(parsed_example[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mdecode_raw(parsed_example[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m], tf\u001b[39m.\u001b[39;49mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(image, (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m1\u001b[39m))  \u001b[39m# Reshape image data to 224x224x1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c61756e6179222c2275736572223a226564756172646f6c756e61227d/home/eduardoluna/Repos/VIS-3D-ZIP/geometry-classifier/luna_clean.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m class_label \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(name[\u001b[39m0\u001b[39m], tf\u001b[39m.\u001b[39mint32)  \u001b[39m# Use the first value in 'name' as a class label\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/parsing_ops.py:969\u001b[0m, in \u001b[0;36mdecode_raw\u001b[0;34m(input_bytes, out_type, little_endian, fixed_length, name)\u001b[0m\n\u001b[1;32m    962\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_parsing_ops\u001b[39m.\u001b[39mdecode_padded_raw(\n\u001b[1;32m    963\u001b[0m       input_bytes,\n\u001b[1;32m    964\u001b[0m       fixed_length\u001b[39m=\u001b[39mfixed_length,\n\u001b[1;32m    965\u001b[0m       out_type\u001b[39m=\u001b[39mout_type,\n\u001b[1;32m    966\u001b[0m       little_endian\u001b[39m=\u001b[39mlittle_endian,\n\u001b[1;32m    967\u001b[0m       name\u001b[39m=\u001b[39mname)\n\u001b[1;32m    968\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_parsing_ops\u001b[39m.\u001b[39;49mdecode_raw(\n\u001b[1;32m    970\u001b[0m       input_bytes, out_type, little_endian\u001b[39m=\u001b[39;49mlittle_endian, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_parsing_ops.py:413\u001b[0m, in \u001b[0;36mdecode_raw\u001b[0;34m(bytes, out_type, little_endian, name)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m    412\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m    414\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mDecodeRaw\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39mbytes\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mout_type\u001b[39;49m\u001b[39m\"\u001b[39;49m, out_type, \u001b[39m\"\u001b[39;49m\u001b[39mlittle_endian\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    415\u001b[0m       little_endian)\n\u001b[1;32m    416\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m    417\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_path = '/home/workspace/geometry-classifier/data/'\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "    \"\"\"\n",
    "    Parses a serialized TFRecord example and extracts image and class label.\n",
    "    \"\"\"\n",
    "    feature_description = {\n",
    "        'name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    name = tf.io.decode_raw(parsed_example['name'], tf.float32)\n",
    "    image = tf.io.decode_raw(parsed_example['image'], tf.float32)\n",
    "    image = tf.reshape(image, (224, 224, 1))  # Reshape image data to 224x224x1\n",
    "    class_label = tf.cast(name[0], tf.int32)  # Use the first value in 'name' as a class label\n",
    "    return image, class_label\n",
    "\n",
    "def serialize_example(image, class_label):\n",
    "    \"\"\"\n",
    "    Serializes an image and class label into a TFRecord example.\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        'name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_label.numpy().tobytes()])),\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.numpy().tobytes()]))\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "def filter_tfrecord(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Reads a TFRecord file, filters out rows with a class label of -1,\n",
    "    and writes the remaining rows to a new TFRecord file.\n",
    "    \"\"\"\n",
    "    # Create a TFRecord writer for the output file\n",
    "    with tf.io.TFRecordWriter(output_path, options=\"GZIP\") as writer:\n",
    "        raw_dataset = tf.data.TFRecordDataset(input_path, compression_type=\"GZIP\")\n",
    "        for raw_record in raw_dataset:\n",
    "            image, class_label = parse_tfrecord(raw_record)\n",
    "            if class_label != -1:  # Filter out class -1\n",
    "                serialized_example = serialize_example(tf.convert_to_tensor(image), tf.convert_to_tensor(class_label))\n",
    "                writer.write(serialized_example)\n",
    "\n",
    "def process_tfrecord_folder(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Processes all `.tfrecord.gz` files in a folder, filtering out rows with a class label of -1.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Use glob to find all `.tfrecord.gz` files in the folder\n",
    "    input_files = glob.glob(os.path.join(input_folder, \"*.tfrecord.gz\"))\n",
    "\n",
    "    for input_path in input_files:\n",
    "        file_name = os.path.basename(input_path)\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        print(f\"Processing {input_path} -> {output_path}\")\n",
    "        filter_tfrecord(input_path, output_path)\n",
    "\n",
    "\n",
    "\n",
    "process_tfrecord_folder(base_path+\"tfr_strat100-2min-notfiltered\", base_path+\"tfr_strat100-2min\")\n",
    "\n",
    "#glob.glob(base_path+\"tfr_strat100-2min-notfiltered/*.tfrecord.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
